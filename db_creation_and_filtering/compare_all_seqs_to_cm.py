#!/usr/bin/env python3

# The script compares gene sequences to a specific Rfam covariance model to detect truncated genes
#   and to detect pivotal genes.
# The following Rfam families were used: `RF00177` for bacteria, and `RF01959` for archaea.

## Command line arguments

### Input files:
# 1. `-f / --in-fasta-file` -- an input fasta file of SSU gene sequences.
#   This file is the output of the script `drop_NNN.py`. Mandatory.
# 2. `--prev-tblout` -- a file that is the output of this script, but for previous RiboGrove release.
#   Use of previous data will speed up this script dramatically.
#   If you a creating RiboGrove 8.214, then specify `--prev-tblout <TBLOUT_FILE_FOR_RIBOGROVE_7.213>`.
#   Optional.

### Output files:
# 1. `-o / --outdir` -- the output directory for the output files (mandatory argument):
#   - the file `cmscan_output_table.tblout`. It is a TSV file of comparison statistics:
#       similariry score, alignment coordinates etc.
#   - the file `cmscan_output.txt` -- a txt file, which contains complete output of `cmscan`.

### Dependencies:
# 1. `--cmscan` -- a `cmscan` executable from Infernal (http://eddylab.org/infernal/).
#   We prefer to use the latest version of Infernal here (version 1.1.4). Mandatory.
# 2. `--cmpress` -- a `cmpress` executable from Infernal (http://eddylab.org/infernal/).
#   We prefer to use the latest version of Infernal here (version 1.1.4). Mandatory.
# 3. `-r / --rfam-family-cm` -- an (uncompressed) `.cm` file containing a Rfam's (version 14.6)
#   covariance models: ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.6/Rfam.cm.gz.
#   Here, we prefer to use the latest verison of Rfam (version 14.6). Mandatory.


import os

print(f'\n|=== STARTING SCRIPT `{os.path.basename(__file__)}` ===|\n')


import re
import sys
import argparse
import subprocess as sp

import pandas as pd
from Bio import SeqIO


# == Parse arguments ==

parser = argparse.ArgumentParser()

# Input files

parser.add_argument(
    '-f',
    '--in-fasta-file',
    help='input fasta file of SSU gene sequences',
    required=True
)

parser.add_argument(
    '--prev-tblout',
    help=""".tblout file generated by this script for the previous RiboGrove release
(will increase speed if specified). This file whould be usually named `cmscan_output_table.tblout`""",
    required=False
)

# Output files

parser.add_argument(
    '--outdir',
    help='output directory',
    required=True
)

# Dependencies

parser.add_argument(
    '--cmscan',
    help='cmscan executable',
    required=True
)

parser.add_argument(
    '--cmpress',
    help='cmpress executable',
    required=True
)

parser.add_argument(
    '-r',
    '--rfam-family-cm',
    help=""".cm file containing covariance model of target gene family
  (RF00177 for bacterial ribosomal SSU, RF01959 for archaeal ribosomal SSU)""",
    required=True
)


args = parser.parse_args()

# For convenience
fasta_seqs_fpath = os.path.abspath(args.in_fasta_file)
if not args.prev_tblout is None:
    prev_tblout_fpath = os.path.abspath(args.prev_tblout)
else:
    prev_tblout_fpath = None
# end if
rfam_fpath = os.path.abspath(args.rfam_family_cm)
outdpath = os.path.abspath(args.outdir)
cmscan_fpath = os.path.abspath(args.cmscan)
cmpress_fpath = os.path.abspath(args.cmpress)


# Check existance of all input files and dependencies
for fpath in (fasta_seqs_fpath, rfam_fpath, cmscan_fpath, cmpress_fpath):
    if not os.path.exists(fpath):
        print(f'Error: file `{fpath}` does not exist!')
        sys.exit(1)
    # end if
# enb for

# Check if executables are actually executable
for exec_fpath in (cmscan_fpath, cmpress_fpath):
    if not os.access(exec_fpath, os.X_OK):
        print(f'Error: file `{exec_fpath}` is not executable!')
        sys.exit(1)
    # end if
# end for

# Create output directory if needed
if not os.path.isdir(outdpath):
    try:
        os.makedirs(outdpath)
    except OSError as err:
        print(f'Error: cannot create directory `{outdpath}`')
        sys.exit(1)
    # end try
# end if

# Check if prev_tblout is specified
if not prev_tblout_fpath is None and prev_tblout_fpath != '':
    # A flag variable for convenience
    cached_tblout = True

    if not os.path.exists(prev_tblout_fpath):
        print(f'Error: file `{prev_tblout_fpath}` does not exist!')
        sys.exit(1)
    # end if
else:
    cached_tblout = False
# end if



print(fasta_seqs_fpath)
if cached_tblout:
    print(f'Previous .tblout file: `{prev_tblout_fpath}`')
# end if
print(cmscan_fpath)
print(cmpress_fpath)
print(rfam_fpath)
print()


# Header for reformatted .tblout files
tblout_header = 'target_name\taccession\tquery_name\taccession\tmdl\tmdl_from\tmdl_to\tseq_from\tseq_to\tstrand\ttrunc\tpass\tgc\tbias\tscore\tEvalue\tinc\tdescription_of_target'


def reformat_tblout(tblout_fpath: str, tblout_header: str) -> None:
    # Function reformats .tblout file, which is output of cmscan.
    # Raw .tblout file is awfully formatted: fields are delimited by spaces
    #   (sometimes 2, sometimes 3 etc). And columns names caontain spaces too.
    # We will reformat tis file: rename columns according to `tblout_header`
    #   and replace irregular field delimiter with tabs.

    # Read all lines except of those starting with #
    with open(tblout_fpath, 'rt') as tblout_file:
        lines = list(
            map(
                str.strip,
                filter(
                    lambda x: x[0] != '#',
                    tblout_file.readlines()
                )
            )
        )
    # end with

    # Remove multiple spaces with single space
    for i in range(len(lines)):
        for space_num in range(20, 1, -1):
            lines[i] = lines[i].replace(' '*space_num, ' ')
        # end for
    # end for

    # Remove spaces in important fields with underscores
    for i in range(len(lines)):
        lines[i] = lines[i].replace('Bacterial small subunit ribosomal RNA', 'Bacterial_small_subunit_ribosomal_RNA')
        lines[i] = lines[i].replace('Archaeal small subunit ribosomal RNA', 'Archaeal_small_subunit_ribosomal_RNA')
    # end for

    # Replace spaces with tabs
    for i in range(len(lines)):
        lines[i] = lines[i].replace(' ', '\t')
    # end for

    # Write result lines to original file
    with open(tblout_fpath, 'wt') as tblout_file:
        tblout_file.write(f'{tblout_header}\n')
        tblout_file.write('\n'.join(lines) + '\n')
    # end with
# end def reformat_tblout


def run_cmpress(cmpress_fpath: str, rfam_fpath: str) -> None:
    # Function runs cmpress on rfam .cm file.
    # It is required to run cmscan.

    # Actually run cmpress
    print('Running `cmpress`...')
    cmd = f'{cmpress_fpath} {rfam_fpath}'
    pipe = sp.Popen(cmd, shell=True, stdout=sp.PIPE, stderr=sp.PIPE)
    stdout_stderr = pipe.communicate()

    if pipe.returncode != 0:
        # It something goes wrong -- check the error message
        error_msg = stdout_stderr[1].decode('utf-8')

        # If `error_msg` contains `already_exists_msg_pattern` -- it's ok --
        #   index files exist.
        already_exists_msg_pattern = r'.+ file ({}.+) already exists'.format(rfam_fpath)
        already_exists_obj = re.search(already_exists_msg_pattern, error_msg)
        just_already_exists = not already_exists_obj is None

        if just_already_exists:
            print(error_msg)
            print(f'Removing {already_exists_obj.group(1)}')
            os.unlink(already_exists_obj.group(1))
            run_cmpress(cmpress_fpath, rfam_fpath)
        else:
            # If `error_msg` does not contain `already_exists_msg_pattern` -- oh, we must terminate
            print('Error: cannot cmpress .cm file')
            print(error_msg)
            sys.exit(1)
        # end if
    else:
        # Print piped stdout
        print(stdout_stderr[0].decode('utf-8'))
    # end if
# end def run_cmpress


# == Proceed ==

# Index file with covariance model
run_cmpress(cmpress_fpath, rfam_fpath)


fasta_seqs_fpath_for_cmscan = fasta_seqs_fpath

if cached_tblout:

    print('Loading previous .tblout file')

    # Read seqIDs from previous .tblout file
    prev_tblout_df = pd.read_csv(prev_tblout_fpath, sep='\t')
    cached_seqIDs = set(prev_tblout_df['query_name'])

    # Read all input sequences, without cached sequences
    seq_records = tuple(SeqIO.parse(fasta_seqs_fpath, 'fasta'))
    seqIDs = set(map(lambda r: r.id, seq_records))

    # Find seqIDs of sequences to be processed now by cmscan
    seqIDs_for_cmscan = set(
        filter(
            lambda x: not x in cached_seqIDs,
            seqIDs
        )
    )
    seq_records_for_cmscan = tuple(
        filter(
            lambda r: r.id in seqIDs_for_cmscan,
            seq_records
        )
    )

    # Save cached seqIDs
    cached_seqIDs = seqIDs - seqIDs_for_cmscan
    cached_tblout_df = prev_tblout_df.query('query_name in @cached_seqIDs')

    print(
        '{}/{} sequences are cached in the previous .tblout file' \
            .format(
                len(seq_records) - len(seq_records_for_cmscan),
                len(seq_records)
            )
    )
    print('{} sequences left to be processed by cmscan'.format(len(seq_records_for_cmscan)))

    # Write unprocessed sequences to temporary fasta file
    tmp_fasta_fpath = os.path.join(outdpath, 'tmp.fasta')
    with open(tmp_fasta_fpath, 'wt') as tmp_fasta:
        for record in seq_records_for_cmscan:
            tmp_fasta.write(f'>{record.description}\n{str(record.seq)}\n')
        # end for
    # end with

    fasta_seqs_fpath_for_cmscan = tmp_fasta_fpath

    # Let the garbage collector devour this objects
    del seq_records, seqIDs, seqIDs_for_cmscan, prev_tblout_df, cached_seqIDs
# end if


# Configure paths to output files
output_file = os.path.join(outdpath, 'cmscan_output.txt')
tblout_fpath = os.path.join(outdpath, 'cmscan_output_table.tblout')

# Configure command for cmscan
command = ' '.join([
    cmscan_fpath,
    f'--tblout {tblout_fpath}',
    '--toponly --acc',
    rfam_fpath,
    fasta_seqs_fpath_for_cmscan,
    f'> {output_file}',
    f'2> {output_file}'
])



# == Proceed ==

all_seqs_are_cached = len(seq_records_for_cmscan) == 0
if not all_seqs_are_cached:
    print('Running cmscan command:')
    print(command)
    print('It will take a while: single sequence is processed for ~3 seconds')
    print('To check progress, run this command (it will list all seqIDs of processed sequences):')
    print(f'  grep -c "Query:" {output_file}')

    exit_code = os.system(command)
    if exit_code != 0:
        print('Error!')
        sys.exit(1)
    # end if
# end if

if cached_tblout:
    # Remove temporary fasta file
    try:
        os.unlink(tmp_fasta_fpath)
    except OSError as err:
        print(f'Cannot remove temporary file `{tmp_fasta_fpath}`')
        print(err)
        print('Proceeding anyway\n')
    # end try

    mode = 'w' if all_seqs_are_cached else 'a'

    # Add cached .tblout dataframe rows
    cached_tblout_df.to_csv(
        tblout_fpath,
        sep='\t',
        index=False,
        header=False,
        mode=mode,
        na_rep='NA'
    )
# end if


# Reformat output .tblout table
print(f'Reformatting output file `{tblout_fpath}`...')
reformat_tblout(tblout_fpath, tblout_header)
print('Done')


print('\nCompleted!')
print(output_file)
print(tblout_fpath)
print(f'\n|=== EXITTING SCRIPT `{os.path.basename(__file__)}` ===|\n')
